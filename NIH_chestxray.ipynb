{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbGLzh/HX8OXFboACA3+pt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZaryabRahman/Stability-and-Expression-The-dual-mechanism-of-normalization-in-deep-learning/blob/main/NIH_chestxray.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobilenetV2- mobile net with spatial attention mechanism\n"
      ],
      "metadata": {
        "id": "3TYgWOsNtoa0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.applications.mobilenet import MobileNet\n",
        "from keras.layers import Input, Conv2D, BatchNormalization, multiply, GlobalAveragePooling2D, Dropout, Dense\n",
        "from keras.models import Model\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_attention_and_classifier(input_features, num_labels):\n",
        "    \"\"\"\n",
        "    Creates the spatial attention block and the final classifier.\n",
        "    This block takes feature maps from a base model and produces two outputs.\n",
        "\n",
        "    Args:\n",
        "      input_features: The input tensor (features from the base model).\n",
        "      num_labels: The number of output classes.\n",
        "\n",
        "    Returns:\n",
        "      A tuple containing (classification_output_layer, attention_map_layer).\"\"\"\n",
        "\n",
        "    new_features = BatchNormalization()(input_features)\n",
        "\n",
        "    attention_layer = Conv2D(64, kernel_size=(1, 1), padding='same', activation='elu')(new_features)\n",
        "    attention_layer = Conv2D(32, kernel_size=(1, 1), padding='same', activation='elu')(attention_layer)\n",
        "    attention_map = Conv2D(1,\n",
        "                           kernel_size=(1, 1),\n",
        "                           padding='valid',\n",
        "                           activation='sigmoid',\n",
        "                           name='attention_map')(attention_layer)\n",
        "\n",
        "    mask_features = multiply([attention_map, new_features])\n",
        "    gap_features = GlobalAveragePooling2D()(mask_features)\n",
        "\n",
        "    x = Dropout(0.5)(gap_features)\n",
        "    x = Dense(512, activation='elu')(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    classification_output = Dense(num_labels, activation='sigmoid', name='classification_output')(x)\n",
        "\n",
        "    return classification_output, attention_map\n",
        "\n",
        "input_tensor = Input(shape=t_x.shape[1:])\n",
        "\n",
        "base_mobilenet_model = MobileNet(input_tensor=input_tensor,\n",
        "                                 include_top=False,\n",
        "                                 weights=None)\n",
        "\n",
        "base_model_output = base_mobilenet_model.output\n",
        "\n",
        "final_output, attention_map_output = create_attention_and_classifier(base_model_output, len(all_labels))\n",
        "\n",
        "attention_mobilenet_model = Model(\n",
        "    inputs=input_tensor,\n",
        "    outputs=[final_output, attention_map_output]\n",
        ")\n",
        "\n",
        "attention_mobilenet_model.compile(\n",
        "    optimizer='adam',\n",
        "    loss={'classification_output': 'binary_crossentropy'},\n",
        "    loss_weights={'classification_output': 1.0, 'attention_map': 0.0},\n",
        "    metrics={'classification_output': ['binary_accuracy', 'mae']}\n",
        ")\n",
        "\n",
        "attention_mobilenet_model.summary()"
      ],
      "metadata": {
        "id": "3go-9LsRwu06"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Callback Definition"
      ],
      "metadata": {
        "id": "hmbtoeMFx2vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras import optimizers\n",
        "\n",
        "weight_path = \"{}_mobilenet_attention_weights.best.hdf5\".format('xray_class')\n",
        "\n",
        "early = EarlyStopping(monitor=\"val_classification_output_loss\",\n",
        "                      mode=\"min\",\n",
        "                      patience=5)\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=weight_path,\n",
        "                             monitor='val_classification_output_loss',\n",
        "                             mode='min',\n",
        "                             save_best_only=True,\n",
        "                             save_weights_only=True)\n",
        "\n",
        "callbacks_list = [early, checkpoint]"
      ],
      "metadata": {
        "id": "ymGnGql1xXMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Training"
      ],
      "metadata": {
        "id": "ruOpG4CBx6RS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras import optimizers\n",
        "\n",
        "optimizers_list = [\n",
        "    ('adam', optimizers.Adam())\n",
        "]\n",
        "\n",
        "plt.figure(figsize=(20,5))\n",
        "\n",
        "for optimizer in optimizers_list:\n",
        "    attention_mobilenet_model.compile(\n",
        "        optimizer=optimizer[1],\n",
        "        loss={'classification_output': 'binary_crossentropy'},\n",
        "        loss_weights={'classification_output': 1.0, 'attention_map': 0.0},\n",
        "        metrics={'classification_output': ['binary_accuracy', 'mae']}\n",
        "    )\n",
        "\n",
        "    history = attention_mobilenet_model.fit_generator(train_gen,\n",
        "                                  steps_per_epoch=1000,\n",
        "                                  validation_data=(test_X, test_Y),\n",
        "                                  epochs=50,\n",
        "                                  callbacks=callbacks_list)\n",
        "\n",
        "    plt.plot(history.history['val_classification_output_loss'])\n",
        "\n",
        "plt.legend([x[0] for x in optimizers_list], loc='upper right')\n",
        "plt.title('model validation loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()\n",
        "plt.savefig('optimizer_selection_attention.png', bbox_inches='tight')"
      ],
      "metadata": {
        "id": "-FgFb-hSxZ4u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Attention Mechanism Visualization"
      ],
      "metadata": {
        "id": "fLmVuL2Px83v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "attention_mobilenet_model.load_weights(weight_path)\n",
        "\n",
        "sample_image = test_X[0]\n",
        "image_for_prediction = np.expand_dims(sample_image, axis=0)\n",
        "\n",
        "predictions, attention_map = attention_mobilenet_model.predict(image_for_prediction)\n",
        "attention_heatmap = np.squeeze(attention_map)\n",
        "\n",
        "resized_heatmap = cv2.resize(attention_heatmap, (sample_image.shape[1], sample_image.shape[0]))\n",
        "\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(18, 6))\n",
        "\n",
        "ax1.imshow(sample_image)\n",
        "ax1.set_title('Original Image')\n",
        "ax1.axis('off')\n",
        "\n",
        "ax2.imshow(resized_heatmap, cmap='jet')\n",
        "ax2.set_title('Attention Heatmap')\n",
        "ax2.axis('off')\n",
        "\n",
        "ax3.imshow(sample_image)\n",
        "ax3.imshow(resized_heatmap, cmap='jet', alpha=0.5)\n",
        "ax3.set_title('Image with Attention Overlay')\n",
        "ax3.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Ca4OdVm8xedD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}